{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPA 6: An√°lise Qualitativa das Respostas Abertas\n",
    "\n",
    "## Consulta √† Comunidade UFPE sobre o Uso de Intelig√™ncia Artificial\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo:** Explorar percep√ß√µes, preocupa√ß√µes e sugest√µes em profundidade.\n",
    "\n",
    "**Vari√°veis analisadas (7 quest√µes abertas):**\n",
    "1. Benef√≠cios percebidos no uso da IA\n",
    "2. Riscos e preocupa√ß√µes identificados\n",
    "3. Impacto na produ√ß√£o autoral\n",
    "4. Impacto na integridade acad√™mica\n",
    "5. Medidas para uso √©tico\n",
    "6. Estrutura de governan√ßa\n",
    "7. Sugest√µes e coment√°rios finais\n",
    "\n",
    "**Procedimentos:**\n",
    "1. Realizar leitura explorat√≥ria de amostra representativa (m√≠nimo 10% das respostas)\n",
    "2. Desenvolver codebook inicial com categorias tem√°ticas emergentes\n",
    "3. Aplicar An√°lise de Conte√∫do (Bardin) para categoriza√ß√£o sistem√°tica\n",
    "4. Utilizar t√©cnicas de an√°lise textual para identifica√ß√£o de temas\n",
    "5. Gerar nuvens de palavras e an√°lises de frequ√™ncia\n",
    "6. Selecionar cita√ß√µes representativas para cada tema identificado\n",
    "7. Estratificar an√°lise por v√≠nculo institucional quando pertinente\n",
    "\n",
    "**Produto:** Relat√≥rio de an√°lise de conte√∫do com categorias, frequ√™ncias, cita√ß√µes exemplares e visualiza√ß√µes.\n",
    "\n",
    "**Crit√©rio de Valida√ß√£o:** Satura√ß√£o tem√°tica; coer√™ncia entre categorias e cita√ß√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Requisitos T√©cnicos\n",
    "\n",
    "### Kernel Python\n",
    "- **Python:** 3.9 ou superior\n",
    "- **Kernel recomendado:** `python3` ou ambiente virtual com as depend√™ncias instaladas\n",
    "\n",
    "### Dados de Entrada\n",
    "\n",
    "| Arquivo | Descri√ß√£o | Origem |\n",
    "|---------|-----------|--------|\n",
    "| `dados_limpos_etapa1.xlsx` | Base de dados limpa com 2.164 registros | Etapa 1 |\n",
    "\n",
    "### Dados de Sa√≠da\n",
    "\n",
    "| Arquivo | Descri√ß√£o |\n",
    "|---------|----------|\n",
    "| `qualitativa_etapa6.xlsx` | An√°lise de frequ√™ncia de termos e categorias tem√°ticas |\n",
    "| `amostra_analise_etapa6.xlsx` | Amostra de 10% para an√°lise manual |\n",
    "| `grafico_nuvem_[variavel]_etapa6.png` | Nuvens de palavras por quest√£o |\n",
    "| `grafico_frequencia_termos_etapa6.png` | Termos mais frequentes por quest√£o |\n",
    "| `grafico_comprimento_respostas_etapa6.png` | Distribui√ß√£o do comprimento das respostas |\n",
    "| `citacoes_representativas_etapa6.xlsx` | Cita√ß√µes selecionadas por tema |\n",
    "| `relatorio_qualitativa_etapa6.md` | Relat√≥rio com an√°lise de conte√∫do |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Instala√ß√£o de Depend√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALA√á√ÉO DE DEPEND√äNCIAS\n",
    "# Execute esta c√©lula apenas uma vez para instalar os pacotes necess√°rios\n",
    "# ============================================================================\n",
    "\n",
    "!pip install pandas openpyxl matplotlib seaborn numpy wordcloud nltk unidecode --quiet\n",
    "\n",
    "print(\"‚úÖ Depend√™ncias instaladas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMPORTA√á√ÉO DE BIBLIOTECAS\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Tentar importar bibliotecas opcionais\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_DISPONIVEL = True\n",
    "except ImportError:\n",
    "    WORDCLOUD_DISPONIVEL = False\n",
    "    print(\"‚ö†Ô∏è Biblioteca 'wordcloud' n√£o dispon√≠vel.\")\n",
    "\n",
    "try:\n",
    "    from unidecode import unidecode\n",
    "    UNIDECODE_DISPONIVEL = True\n",
    "except ImportError:\n",
    "    UNIDECODE_DISPONIVEL = False\n",
    "    print(\"‚ö†Ô∏è Biblioteca 'unidecode' n√£o dispon√≠vel.\")\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    NLTK_DISPONIVEL = True\n",
    "except:\n",
    "    NLTK_DISPONIVEL = False\n",
    "    print(\"‚ö†Ô∏è Biblioteca 'nltk' n√£o dispon√≠vel ou erro no download.\")\n",
    "\n",
    "# Configura√ß√µes de exibi√ß√£o\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"\\nBibliotecas carregadas com sucesso!\")\n",
    "print(f\"  ‚Ä¢ Pandas: {pd.__version__}\")\n",
    "print(f\"  ‚Ä¢ WordCloud: {'Dispon√≠vel' if WORDCLOUD_DISPONIVEL else 'N√£o dispon√≠vel'}\")\n",
    "print(f\"  ‚Ä¢ NLTK: {'Dispon√≠vel' if NLTK_DISPONIVEL else 'N√£o dispon√≠vel'}\")\n",
    "print(f\"  ‚Ä¢ Unidecode: {'Dispon√≠vel' if UNIDECODE_DISPONIVEL else 'N√£o dispon√≠vel'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURA√á√ÉO DE ARQUIVOS DE ENTRADA E SA√çDA\n",
    "# ============================================================================\n",
    "\n",
    "# Arquivo de entrada (gerado na Etapa 1)\n",
    "ARQUIVO_ENTRADA = \"dados_limpos_etapa1.xlsx\"\n",
    "\n",
    "# Arquivos de sa√≠da\n",
    "ARQUIVO_SAIDA_EXCEL = \"qualitativa_etapa6.xlsx\"\n",
    "ARQUIVO_SAIDA_AMOSTRA = \"amostra_analise_etapa6.xlsx\"\n",
    "ARQUIVO_SAIDA_CITACOES = \"citacoes_representativas_etapa6.xlsx\"\n",
    "ARQUIVO_SAIDA_RELATORIO = \"relatorio_qualitativa_etapa6.md\"\n",
    "\n",
    "# Percentual da amostra para an√°lise manual\n",
    "PERCENTUAL_AMOSTRA = 0.10  # 10%\n",
    "\n",
    "# Seed para reprodutibilidade\n",
    "SEED = 42\n",
    "\n",
    "print(\"Configura√ß√£o de arquivos:\")\n",
    "print(f\"  üì• Entrada: {ARQUIVO_ENTRADA}\")\n",
    "print(f\"  üì§ Sa√≠das:  {ARQUIVO_SAIDA_EXCEL}\")\n",
    "print(f\"            {ARQUIVO_SAIDA_AMOSTRA}\")\n",
    "print(f\"            {ARQUIVO_SAIDA_CITACOES}\")\n",
    "print(f\"            {ARQUIVO_SAIDA_RELATORIO}\")\n",
    "print(f\"  üìä Amostra para an√°lise manual: {PERCENTUAL_AMOSTRA*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados limpos da Etapa 1\n",
    "try:\n",
    "    df = pd.read_excel(ARQUIVO_ENTRADA)\n",
    "    print(f\"‚úÖ Dados carregados com sucesso!\")\n",
    "    print(f\"   Registros: {len(df)}\")\n",
    "    print(f\"   Vari√°veis: {len(df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERRO: Arquivo '{ARQUIVO_ENTRADA}' n√£o encontrado!\")\n",
    "    print(f\"   Certifique-se de que a Etapa 1 foi executada e o arquivo est√° no diret√≥rio correto.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IDENTIFICA√á√ÉO DAS VARI√ÅVEIS ABERTAS\n",
    "# ============================================================================\n",
    "\n",
    "# Dicion√°rio com as vari√°veis abertas e suas descri√ß√µes\n",
    "variaveis_abertas = {\n",
    "    'Beneficios_Percebidos': {\n",
    "        'descricao': 'Quais benef√≠cios voc√™ percebe no uso de IA?',\n",
    "        'nome_curto': 'Benef√≠cios'\n",
    "    },\n",
    "    'Riscos_Preocupacoes': {\n",
    "        'descricao': 'Quais riscos e preocupa√ß√µes voc√™ identifica?',\n",
    "        'nome_curto': 'Riscos'\n",
    "    },\n",
    "    'Impacto_Producao_Autoral': {\n",
    "        'descricao': 'Como a IA impacta a produ√ß√£o autoral?',\n",
    "        'nome_curto': 'Produ√ß√£o Autoral'\n",
    "    },\n",
    "    'Impacto_Integridade_Academica': {\n",
    "        'descricao': 'Como a IA impacta a integridade acad√™mica?',\n",
    "        'nome_curto': 'Integridade Acad√™mica'\n",
    "    },\n",
    "    'Medidas_Uso_Etico': {\n",
    "        'descricao': 'Quais medidas devem ser adotadas para uso √©tico?',\n",
    "        'nome_curto': 'Medidas √âticas'\n",
    "    },\n",
    "    'Estrutura_Governanca': {\n",
    "        'descricao': 'Como deve ser a estrutura de governan√ßa?',\n",
    "        'nome_curto': 'Governan√ßa'\n",
    "    },\n",
    "    'Comentarios_Finais': {\n",
    "        'descricao': 'Sugest√µes e coment√°rios finais',\n",
    "        'nome_curto': 'Coment√°rios Finais'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VARI√ÅVEIS ABERTAS PARA AN√ÅLISE QUALITATIVA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "estatisticas_variaveis = []\n",
    "\n",
    "for var, info in variaveis_abertas.items():\n",
    "    n_respostas = df[var].notna().sum()\n",
    "    pct_respostas = n_respostas / len(df) * 100\n",
    "    \n",
    "    # Calcular comprimento m√©dio das respostas\n",
    "    comprimentos = df[var].dropna().astype(str).str.len()\n",
    "    comp_medio = comprimentos.mean() if len(comprimentos) > 0 else 0\n",
    "    \n",
    "    estatisticas_variaveis.append({\n",
    "        'Vari√°vel': var,\n",
    "        'Nome Curto': info['nome_curto'],\n",
    "        'Respostas': n_respostas,\n",
    "        '% Preenchimento': round(pct_respostas, 1),\n",
    "        'Comp. M√©dio (chars)': round(comp_medio, 0)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüìå {info['nome_curto']}\")\n",
    "    print(f\"   Vari√°vel: {var}\")\n",
    "    print(f\"   Respostas v√°lidas: {n_respostas} ({pct_respostas:.1f}%)\")\n",
    "    print(f\"   Comprimento m√©dio: {comp_medio:.0f} caracteres\")\n",
    "\n",
    "df_estatisticas = pd.DataFrame(estatisticas_variaveis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Fun√ß√µes Auxiliares para An√°lise Textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STOPWORDS EM PORTUGU√äS (lista expandida)\n",
    "# ============================================================================\n",
    "\n",
    "# Stopwords b√°sicas em portugu√™s\n",
    "STOPWORDS_PT = {\n",
    "    'a', '√†', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo',\n",
    "    'as', '√†s', 'at√©', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas',\n",
    "    'dele', 'deles', 'depois', 'do', 'dos', 'e', '√©', 'ela', 'elas', 'ele',\n",
    "    'eles', 'em', 'entre', 'era', 'eram', '√©ramos', 'essa', 'essas', 'esse',\n",
    "    'esses', 'esta', 'est√°', 'estamos', 'est√£o', 'estar', 'estas', 'estava',\n",
    "    'estavam', 'est√°vamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes',\n",
    "    'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram',\n",
    "    'estiv√©ramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem',\n",
    "    'estiv√©ssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram',\n",
    "    'f√¥ramos', 'forem', 'formos', 'fosse', 'fossem', 'f√¥ssemos', 'fui',\n",
    "    'h√°', 'haja', 'hajam', 'hajamos', 'h√£o', 'havemos', 'haver', 'hei',\n",
    "    'houve', 'houvemos', 'houver', 'houvera', 'houver√°', 'houveram',\n",
    "    'houv√©ramos', 'houver√£o', 'houverei', 'houverem', 'houveremos',\n",
    "    'houveria', 'houveriam', 'houver√≠amos', 'houvermos', 'houvesse',\n",
    "    'houvessem', 'houv√©ssemos', 'isso', 'isto', 'j√°', 'lhe', 'lhes', 'lo',\n",
    "    'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito',\n",
    "    'muita', 'muitas', 'muitos', 'na', 'n√£o', 'nas', 'nem', 'no', 'nos',\n",
    "    'n√≥s', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os',\n",
    "    'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando',\n",
    "    'que', 'quem', 's√£o', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser',\n",
    "    'ser√°', 'ser√£o', 'serei', 'seremos', 'seria', 'seriam', 'ser√≠amos',\n",
    "    'seu', 'seus', 's√≥', 'somos', 'sou', 'sua', 'suas', 'tamb√©m', 'te',\n",
    "    'tem', 't√©m', 'temos', 'tendo', 'tenha', 'tenham', 'tenhamos', 'tenho',\n",
    "    'ter', 'ter√°', 'ter√£o', 'terei', 'teremos', 'teria', 'teriam',\n",
    "    'ter√≠amos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 't√≠nhamos',\n",
    "    'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tiv√©ramos', 'tiverem',\n",
    "    'tivermos', 'tivesse', 'tivessem', 'tiv√©ssemos', 'tu', 'tua', 'tuas',\n",
    "    'um', 'uma', 'umas', 'uns', 'voc√™', 'voc√™s', 'vos',\n",
    "    # Adicionais comuns em respostas de pesquisa\n",
    "    'ser', 'pode', 'podem', 'poder', 'fazer', 'uso', 'usar', 'utilizar',\n",
    "    'forma', 'modo', 'tipo', 'coisa', 'coisas', 'vez', 'vezes', 'caso',\n",
    "    'casos', 'exemplo', 'alguns', 'algumas', 'algo', 'ainda', 'assim',\n",
    "    'bem', 'cada', 'onde', 'porque', 'pois', 'ent√£o', 'por√©m', 'contudo',\n",
    "    'apenas', 'sobre', 'todo', 'toda', 'todos', 'todas', 'outro', 'outra',\n",
    "    'outros', 'outras', 'mesmo', 'mesma', 'mesmos', 'mesmas', 'pr√≥prio',\n",
    "    'pr√≥pria', 'dia', 'dias', 'ano', 'anos', 'parte', 'partes', 'lado',\n",
    "    'grande', 'maior', 'menor', 'melhor', 'pior', 'bom', 'boa', 'bons',\n",
    "    'boas', 'mau', 'm√°', 'maus', 'm√°s', 'novo', 'nova', 'novos', 'novas',\n",
    "    'primeiro', 'primeira', 'segundo', 'segunda', '√∫ltimo', '√∫ltima',\n",
    "    'sim', 'nao', 'talvez', 'sempre', 'nunca', 'aqui', 'ali', 'l√°', 'c√°',\n",
    "    'agora', 'hoje', 'ontem', 'amanh√£', 'antes', 'depois', 'durante',\n",
    "    'while', 'the', 'and', 'of', 'to', 'in', 'is', 'it', 'that', 'for',\n",
    "    'acredito', 'acho', 'penso', 'creio', 'entendo', 'considero',\n",
    "    'ia', 'intelig√™ncia', 'artificial', 'inteligencia', 'ufpe'\n",
    "}\n",
    "\n",
    "# Adicionar stopwords do NLTK se dispon√≠vel\n",
    "if NLTK_DISPONIVEL:\n",
    "    try:\n",
    "        STOPWORDS_PT = STOPWORDS_PT.union(set(stopwords.words('portuguese')))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"‚úÖ {len(STOPWORDS_PT)} stopwords carregadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FUN√á√ïES DE PR√â-PROCESSAMENTO DE TEXTO\n",
    "# ============================================================================\n",
    "\n",
    "def limpar_texto(texto):\n",
    "    \"\"\"\n",
    "    Limpa e normaliza um texto para an√°lise.\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    \n",
    "    texto = str(texto).lower()\n",
    "    \n",
    "    # Remover acentos se unidecode dispon√≠vel\n",
    "    if UNIDECODE_DISPONIVEL:\n",
    "        texto = unidecode(texto)\n",
    "    \n",
    "    # Remover pontua√ß√£o e n√∫meros\n",
    "    texto = re.sub(r'[^a-z√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±\\s]', ' ', texto)\n",
    "    \n",
    "    # Remover espa√ßos m√∫ltiplos\n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "\n",
    "def tokenizar(texto, remover_stopwords=True, min_length=3):\n",
    "    \"\"\"\n",
    "    Tokeniza um texto em palavras individuais.\n",
    "    \"\"\"\n",
    "    texto_limpo = limpar_texto(texto)\n",
    "    \n",
    "    if not texto_limpo:\n",
    "        return []\n",
    "    \n",
    "    # Tokenizar\n",
    "    palavras = texto_limpo.split()\n",
    "    \n",
    "    # Filtrar\n",
    "    if remover_stopwords:\n",
    "        palavras = [p for p in palavras if p not in STOPWORDS_PT]\n",
    "    \n",
    "    # Filtrar por comprimento m√≠nimo\n",
    "    palavras = [p for p in palavras if len(p) >= min_length]\n",
    "    \n",
    "    return palavras\n",
    "\n",
    "\n",
    "def extrair_ngramas(texto, n=2):\n",
    "    \"\"\"\n",
    "    Extrai n-gramas de um texto.\n",
    "    \"\"\"\n",
    "    palavras = tokenizar(texto, remover_stopwords=False, min_length=2)\n",
    "    \n",
    "    if len(palavras) < n:\n",
    "        return []\n",
    "    \n",
    "    ngramas = []\n",
    "    for i in range(len(palavras) - n + 1):\n",
    "        ngrama = ' '.join(palavras[i:i+n])\n",
    "        # Verificar se pelo menos uma palavra n√£o √© stopword\n",
    "        palavras_ngrama = ngrama.split()\n",
    "        if any(p not in STOPWORDS_PT for p in palavras_ngrama):\n",
    "            ngramas.append(ngrama)\n",
    "    \n",
    "    return ngramas\n",
    "\n",
    "\n",
    "def calcular_frequencia_termos(serie, top_n=30, min_freq=5):\n",
    "    \"\"\"\n",
    "    Calcula a frequ√™ncia de termos em uma s√©rie de textos.\n",
    "    \"\"\"\n",
    "    todas_palavras = []\n",
    "    \n",
    "    for texto in serie.dropna():\n",
    "        palavras = tokenizar(texto)\n",
    "        todas_palavras.extend(palavras)\n",
    "    \n",
    "    contagem = Counter(todas_palavras)\n",
    "    \n",
    "    # Filtrar por frequ√™ncia m√≠nima\n",
    "    contagem = {k: v for k, v in contagem.items() if v >= min_freq}\n",
    "    \n",
    "    # Criar DataFrame\n",
    "    df_freq = pd.DataFrame(contagem.items(), columns=['Termo', 'Frequ√™ncia'])\n",
    "    df_freq = df_freq.sort_values('Frequ√™ncia', ascending=False).head(top_n)\n",
    "    df_freq['Ranking'] = range(1, len(df_freq) + 1)\n",
    "    df_freq = df_freq[['Ranking', 'Termo', 'Frequ√™ncia']]\n",
    "    \n",
    "    return df_freq\n",
    "\n",
    "\n",
    "def calcular_frequencia_bigramas(serie, top_n=20, min_freq=5):\n",
    "    \"\"\"\n",
    "    Calcula a frequ√™ncia de bigramas em uma s√©rie de textos.\n",
    "    \"\"\"\n",
    "    todos_bigramas = []\n",
    "    \n",
    "    for texto in serie.dropna():\n",
    "        bigramas = extrair_ngramas(texto, n=2)\n",
    "        todos_bigramas.extend(bigramas)\n",
    "    \n",
    "    contagem = Counter(todos_bigramas)\n",
    "    \n",
    "    # Filtrar por frequ√™ncia m√≠nima\n",
    "    contagem = {k: v for k, v in contagem.items() if v >= min_freq}\n",
    "    \n",
    "    # Criar DataFrame\n",
    "    df_freq = pd.DataFrame(contagem.items(), columns=['Bigrama', 'Frequ√™ncia'])\n",
    "    df_freq = df_freq.sort_values('Frequ√™ncia', ascending=False).head(top_n)\n",
    "    df_freq['Ranking'] = range(1, len(df_freq) + 1)\n",
    "    df_freq = df_freq[['Ranking', 'Bigrama', 'Frequ√™ncia']]\n",
    "    \n",
    "    return df_freq\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de pr√©-processamento carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FUN√á√ïES PARA SELE√á√ÉO DE CITA√á√ïES REPRESENTATIVAS\n",
    "# ============================================================================\n",
    "\n",
    "def selecionar_citacoes(serie, termos_busca=None, n_citacoes=5, min_chars=50, max_chars=500):\n",
    "    \"\"\"\n",
    "    Seleciona cita√ß√µes representativas de uma s√©rie de textos.\n",
    "    Se termos_busca fornecidos, prioriza respostas que contenham esses termos.\n",
    "    \"\"\"\n",
    "    respostas = serie.dropna().astype(str)\n",
    "    \n",
    "    # Filtrar por comprimento\n",
    "    respostas = respostas[(respostas.str.len() >= min_chars) & (respostas.str.len() <= max_chars)]\n",
    "    \n",
    "    if len(respostas) == 0:\n",
    "        return []\n",
    "    \n",
    "    if termos_busca:\n",
    "        # Priorizar respostas com termos de busca\n",
    "        def contem_termos(texto):\n",
    "            texto_lower = texto.lower()\n",
    "            return sum(1 for termo in termos_busca if termo.lower() in texto_lower)\n",
    "        \n",
    "        respostas_ordenadas = respostas.copy()\n",
    "        scores = respostas_ordenadas.apply(contem_termos)\n",
    "        respostas_ordenadas = respostas_ordenadas[scores > 0]\n",
    "        \n",
    "        if len(respostas_ordenadas) >= n_citacoes:\n",
    "            return respostas_ordenadas.sample(n=n_citacoes, random_state=SEED).tolist()\n",
    "    \n",
    "    # Selecionar aleatoriamente\n",
    "    n_selecionar = min(n_citacoes, len(respostas))\n",
    "    return respostas.sample(n=n_selecionar, random_state=SEED).tolist()\n",
    "\n",
    "\n",
    "def selecionar_citacoes_por_vinculo(df, variavel, n_por_vinculo=2):\n",
    "    \"\"\"\n",
    "    Seleciona cita√ß√µes representativas estratificadas por v√≠nculo.\n",
    "    \"\"\"\n",
    "    citacoes = []\n",
    "    \n",
    "    for vinculo in df['Vinculo_Padronizado'].dropna().unique():\n",
    "        df_vinculo = df[df['Vinculo_Padronizado'] == vinculo]\n",
    "        cits = selecionar_citacoes(df_vinculo[variavel], n_citacoes=n_por_vinculo)\n",
    "        \n",
    "        for cit in cits:\n",
    "            citacoes.append({\n",
    "                'V√≠nculo': vinculo,\n",
    "                'Cita√ß√£o': cit\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(citacoes)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de sele√ß√£o de cita√ß√µes carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. An√°lise Explorat√≥ria das Respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ESTAT√çSTICAS DESCRITIVAS DAS RESPOSTAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ESTAT√çSTICAS DESCRITIVAS DAS RESPOSTAS ABERTAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(df_estatisticas.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DISTRIBUI√á√ÉO DO COMPRIMENTO DAS RESPOSTAS\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (var, info) in enumerate(variaveis_abertas.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    comprimentos = df[var].dropna().astype(str).str.len()\n",
    "    \n",
    "    if len(comprimentos) > 0:\n",
    "        ax.hist(comprimentos, bins=30, color='steelblue', edgecolor='white', alpha=0.7)\n",
    "        ax.axvline(comprimentos.median(), color='red', linestyle='--', label=f'Mediana: {comprimentos.median():.0f}')\n",
    "        ax.set_title(info['nome_curto'], fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Caracteres')\n",
    "        ax.set_ylabel('Frequ√™ncia')\n",
    "        ax.legend(fontsize=8)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Sem dados', ha='center', va='center')\n",
    "        ax.set_title(info['nome_curto'], fontsize=10)\n",
    "\n",
    "# Remover subplot extra\n",
    "axes[7].axis('off')\n",
    "\n",
    "plt.suptitle('Distribui√ß√£o do Comprimento das Respostas (em caracteres)', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('grafico_comprimento_respostas_etapa6.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nGr√°fico salvo como: grafico_comprimento_respostas_etapa6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. An√°lise de Frequ√™ncia de Termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FREQU√äNCIA DE TERMOS PARA CADA QUEST√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TERMOS MAIS FREQUENTES POR QUEST√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "frequencias_termos = {}\n",
    "\n",
    "for var, info in variaveis_abertas.items():\n",
    "    print(f\"\\nüìå {info['nome_curto']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    freq = calcular_frequencia_termos(df[var], top_n=15, min_freq=10)\n",
    "    frequencias_termos[var] = freq\n",
    "    \n",
    "    if len(freq) > 0:\n",
    "        print(freq.to_string(index=False))\n",
    "    else:\n",
    "        print(\"   Nenhum termo com frequ√™ncia suficiente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GR√ÅFICO DE TERMOS MAIS FREQUENTES (TOP 10 DE CADA)\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "cores = plt.cm.Set2(np.linspace(0, 1, 7))\n",
    "\n",
    "for idx, (var, info) in enumerate(variaveis_abertas.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    freq = frequencias_termos[var].head(10)\n",
    "    \n",
    "    if len(freq) > 0:\n",
    "        bars = ax.barh(freq['Termo'], freq['Frequ√™ncia'], color=cores[idx], edgecolor='white')\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('Frequ√™ncia')\n",
    "        ax.set_title(info['nome_curto'], fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Labels nas barras\n",
    "        for bar in bars:\n",
    "            ax.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{int(bar.get_width())}', va='center', fontsize=8)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Dados insuficientes', ha='center', va='center')\n",
    "        ax.set_title(info['nome_curto'], fontsize=11)\n",
    "\n",
    "# Remover subplot extra\n",
    "axes[7].axis('off')\n",
    "\n",
    "plt.suptitle('Top 10 Termos Mais Frequentes por Quest√£o', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('grafico_frequencia_termos_etapa6.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nGr√°fico salvo como: grafico_frequencia_termos_etapa6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Nuvens de Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# NUVENS DE PALAVRAS PARA CADA QUEST√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "if WORDCLOUD_DISPONIVEL:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colormaps = ['Blues', 'Greens', 'Oranges', 'Purples', 'Reds', 'YlOrBr', 'BuGn']\n",
    "    \n",
    "    for idx, (var, info) in enumerate(variaveis_abertas.items()):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Concatenar todas as respostas\n",
    "        textos = df[var].dropna().astype(str)\n",
    "        texto_completo = ' '.join([limpar_texto(t) for t in textos])\n",
    "        \n",
    "        if texto_completo.strip():\n",
    "            # Gerar nuvem de palavras\n",
    "            wordcloud = WordCloud(\n",
    "                width=800, height=400,\n",
    "                background_color='white',\n",
    "                stopwords=STOPWORDS_PT,\n",
    "                colormap=colormaps[idx],\n",
    "                max_words=100,\n",
    "                min_font_size=10,\n",
    "                random_state=SEED\n",
    "            ).generate(texto_completo)\n",
    "            \n",
    "            ax.imshow(wordcloud, interpolation='bilinear')\n",
    "            ax.axis('off')\n",
    "            ax.set_title(info['nome_curto'], fontsize=12, fontweight='bold')\n",
    "            \n",
    "            # Salvar nuvem individual\n",
    "            fig_individual, ax_individual = plt.subplots(figsize=(10, 5))\n",
    "            ax_individual.imshow(wordcloud, interpolation='bilinear')\n",
    "            ax_individual.axis('off')\n",
    "            ax_individual.set_title(info['nome_curto'], fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            nome_arquivo = f\"grafico_nuvem_{var.lower()}_etapa6.png\"\n",
    "            plt.savefig(nome_arquivo, dpi=150, bbox_inches='tight')\n",
    "            plt.close(fig_individual)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'Sem dados', ha='center', va='center')\n",
    "            ax.set_title(info['nome_curto'], fontsize=12)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    # Remover subplot extra\n",
    "    axes[7].axis('off')\n",
    "    \n",
    "    plt.suptitle('Nuvens de Palavras - Respostas Abertas', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('grafico_nuvens_completo_etapa6.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nNuvens de palavras salvas!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nuvens de palavras n√£o geradas (biblioteca 'wordcloud' n√£o dispon√≠vel).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. An√°lise de Bigramas (Express√µes Frequentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BIGRAMAS MAIS FREQUENTES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXPRESS√ïES (BIGRAMAS) MAIS FREQUENTES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "frequencias_bigramas = {}\n",
    "\n",
    "for var, info in variaveis_abertas.items():\n",
    "    print(f\"\\nüìå {info['nome_curto']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    freq_bi = calcular_frequencia_bigramas(df[var], top_n=10, min_freq=10)\n",
    "    frequencias_bigramas[var] = freq_bi\n",
    "    \n",
    "    if len(freq_bi) > 0:\n",
    "        print(freq_bi.to_string(index=False))\n",
    "    else:\n",
    "        print(\"   Nenhum bigrama com frequ√™ncia suficiente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Gera√ß√£o de Amostra para An√°lise Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GERA√á√ÉO DE AMOSTRA ESTRATIFICADA (10%) PARA AN√ÅLISE MANUAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"GERA√á√ÉO DE AMOSTRA PARA AN√ÅLISE MANUAL (CODIFICA√á√ÉO)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calcular tamanho da amostra por v√≠nculo (estratificada)\n",
    "n_amostra = int(len(df) * PERCENTUAL_AMOSTRA)\n",
    "\n",
    "# Amostragem estratificada por v√≠nculo\n",
    "amostra = df.groupby('Vinculo_Padronizado', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=PERCENTUAL_AMOSTRA, random_state=SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nTamanho da amostra: {len(amostra)} registros ({len(amostra)/len(df)*100:.1f}% do total)\")\n",
    "print(f\"\\nDistribui√ß√£o por v√≠nculo:\")\n",
    "print(amostra['Vinculo_Padronizado'].value_counts())\n",
    "\n",
    "# Selecionar apenas vari√°veis relevantes para an√°lise\n",
    "colunas_amostra = ['Vinculo_Padronizado', 'Centro_Unidade'] + list(variaveis_abertas.keys())\n",
    "amostra_exportar = amostra[colunas_amostra].copy()\n",
    "\n",
    "# Adicionar colunas para codifica√ß√£o manual\n",
    "for var in variaveis_abertas.keys():\n",
    "    amostra_exportar[f'{var}_CODIGO'] = ''  # Coluna para c√≥digo tem√°tico\n",
    "    amostra_exportar[f'{var}_OBS'] = ''     # Coluna para observa√ß√µes\n",
    "\n",
    "# Salvar amostra\n",
    "amostra_exportar.to_excel(ARQUIVO_SAIDA_AMOSTRA, index=False)\n",
    "print(f\"\\n‚úÖ Amostra salva em: {ARQUIVO_SAIDA_AMOSTRA}\")\n",
    "print(f\"   Use este arquivo para codifica√ß√£o manual das respostas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Sele√ß√£o de Cita√ß√µes Representativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SELE√á√ÉO DE CITA√á√ïES REPRESENTATIVAS POR QUEST√ÉO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CITA√á√ïES REPRESENTATIVAS POR QUEST√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "todas_citacoes = []\n",
    "\n",
    "for var, info in variaveis_abertas.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìå {info['nome_curto'].upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Selecionar cita√ß√µes\n",
    "    citacoes = selecionar_citacoes(df[var], n_citacoes=5, min_chars=80, max_chars=400)\n",
    "    \n",
    "    for i, cit in enumerate(citacoes, 1):\n",
    "        print(f\"\\n  [{i}] \\\"{cit}\\\"\")\n",
    "        todas_citacoes.append({\n",
    "            'Quest√£o': info['nome_curto'],\n",
    "            'Vari√°vel': var,\n",
    "            'Cita√ß√£o': cit\n",
    "        })\n",
    "\n",
    "# Criar DataFrame com cita√ß√µes\n",
    "df_citacoes = pd.DataFrame(todas_citacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CITA√á√ïES ESTRATIFICADAS POR V√çNCULO (para as 3 principais quest√µes)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CITA√á√ïES POR V√çNCULO INSTITUCIONAL (QUEST√ïES PRINCIPAIS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "questoes_principais = ['Beneficios_Percebidos', 'Riscos_Preocupacoes', 'Medidas_Uso_Etico']\n",
    "\n",
    "citacoes_vinculo = []\n",
    "\n",
    "for var in questoes_principais:\n",
    "    info = variaveis_abertas[var]\n",
    "    print(f\"\\nüìå {info['nome_curto']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    df_cit_vinculo = selecionar_citacoes_por_vinculo(df, var, n_por_vinculo=1)\n",
    "    \n",
    "    for _, row in df_cit_vinculo.iterrows():\n",
    "        print(f\"\\n  [{row['V√≠nculo']}]\")\n",
    "        print(f\"  \\\"{row['Cita√ß√£o'][:200]}{'...' if len(row['Cita√ß√£o']) > 200 else ''}\\\"\")\n",
    "        \n",
    "        citacoes_vinculo.append({\n",
    "            'Quest√£o': info['nome_curto'],\n",
    "            'V√≠nculo': row['V√≠nculo'],\n",
    "            'Cita√ß√£o': row['Cita√ß√£o']\n",
    "        })\n",
    "\n",
    "df_citacoes_vinculo = pd.DataFrame(citacoes_vinculo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Categoriza√ß√£o Tem√°tica Preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CATEGORIZA√á√ÉO TEM√ÅTICA BASEADA EM PALAVRAS-CHAVE\n",
    "# ============================================================================\n",
    "\n",
    "# Definir categorias tem√°ticas e palavras-chave associadas\n",
    "categorias_tematicas = {\n",
    "    'Beneficios_Percebidos': {\n",
    "        'Produtividade/Efici√™ncia': ['produtividade', 'eficiencia', 'rapido', 'rapidez', 'tempo', 'agilidade', 'otimizar', 'automatizar'],\n",
    "        'Apoio √† Pesquisa': ['pesquisa', 'pesquisar', 'busca', 'buscar', 'informacao', 'dados', 'analise', 'analisar'],\n",
    "        'Apoio ao Ensino/Aprendizagem': ['aprendizado', 'aprender', 'estudar', 'ensino', 'ensinar', 'didatico', 'educacao'],\n",
    "        'Escrita/Reda√ß√£o': ['escrever', 'escrita', 'texto', 'redacao', 'revisar', 'revisao', 'corrigir', 'gramatica'],\n",
    "        'Criatividade/Inova√ß√£o': ['criatividade', 'criativo', 'inovacao', 'inovar', 'ideias', 'inspiracao'],\n",
    "        'Acessibilidade': ['acessibilidade', 'acessivel', 'inclusao', 'inclusivo', 'democratizar']\n",
    "    },\n",
    "    'Riscos_Preocupacoes': {\n",
    "        'Pl√°gio/Integridade': ['plagio', 'copiar', 'copia', 'integridade', 'autoria', 'original', 'originalidade'],\n",
    "        'Depend√™ncia/Pregui√ßa': ['dependencia', 'dependente', 'preguica', 'acomodacao', 'passivo', 'pensar'],\n",
    "        'Desinforma√ß√£o': ['desinformacao', 'fake', 'falso', 'incorreto', 'erro', 'erros', 'confiabilidade'],\n",
    "        'Desemprego/Substitui√ß√£o': ['emprego', 'desemprego', 'substituir', 'substituicao', 'trabalho', 'profissional'],\n",
    "        'Privacidade/Dados': ['privacidade', 'dados', 'seguranca', 'vazamento', 'confidencial'],\n",
    "        'Vi√©s/Discrimina√ß√£o': ['vies', 'discriminacao', 'preconceito', 'racismo', 'desigualdade']\n",
    "    },\n",
    "    'Medidas_Uso_Etico': {\n",
    "        'Regulamenta√ß√£o/Normas': ['regulamentacao', 'regulamentar', 'norma', 'normas', 'regra', 'regras', 'politica', 'politicas'],\n",
    "        'Capacita√ß√£o/Forma√ß√£o': ['capacitacao', 'capacitar', 'formacao', 'formar', 'treinamento', 'treinar', 'curso', 'cursos'],\n",
    "        'Transpar√™ncia': ['transparencia', 'transparente', 'declarar', 'declaracao', 'informar', 'citar'],\n",
    "        'Conscientiza√ß√£o': ['conscientizacao', 'conscientizar', 'sensibilizar', 'orientar', 'orientacao'],\n",
    "        'Fiscaliza√ß√£o/Controle': ['fiscalizacao', 'fiscalizar', 'controle', 'monitorar', 'monitoramento', 'verificar']\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def categorizar_resposta(texto, categorias):\n",
    "    \"\"\"\n",
    "    Categoriza uma resposta com base em palavras-chave.\n",
    "    Retorna lista de categorias identificadas.\n",
    "    \"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return []\n",
    "    \n",
    "    texto_limpo = limpar_texto(texto)\n",
    "    categorias_encontradas = []\n",
    "    \n",
    "    for categoria, palavras in categorias.items():\n",
    "        for palavra in palavras:\n",
    "            if palavra in texto_limpo:\n",
    "                categorias_encontradas.append(categoria)\n",
    "                break  # Evitar contar mesma categoria m√∫ltiplas vezes\n",
    "    \n",
    "    return categorias_encontradas\n",
    "\n",
    "\n",
    "# Aplicar categoriza√ß√£o para as quest√µes principais\n",
    "print(\"=\" * 80)\n",
    "print(\"CATEGORIZA√á√ÉO TEM√ÅTICA PRELIMINAR (baseada em palavras-chave)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "resultados_categorizacao = {}\n",
    "\n",
    "for var, categorias in categorias_tematicas.items():\n",
    "    info = variaveis_abertas[var]\n",
    "    print(f\"\\nüìå {info['nome_curto']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Categorizar cada resposta\n",
    "    todas_categorias = []\n",
    "    for texto in df[var].dropna():\n",
    "        cats = categorizar_resposta(texto, categorias)\n",
    "        todas_categorias.extend(cats)\n",
    "    \n",
    "    # Contar frequ√™ncia de cada categoria\n",
    "    contagem = Counter(todas_categorias)\n",
    "    n_respondentes = df[var].notna().sum()\n",
    "    \n",
    "    df_cat = pd.DataFrame(contagem.items(), columns=['Categoria', 'Men√ß√µes'])\n",
    "    df_cat = df_cat.sort_values('Men√ß√µes', ascending=False)\n",
    "    df_cat['% Respondentes'] = (df_cat['Men√ß√µes'] / n_respondentes * 100).round(1)\n",
    "    \n",
    "    resultados_categorizacao[var] = df_cat\n",
    "    \n",
    "    print(df_cat.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GR√ÅFICO DE CATEGORIAS TEM√ÅTICAS\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "cores_cat = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "for idx, (var, df_cat) in enumerate(resultados_categorizacao.items()):\n",
    "    ax = axes[idx]\n",
    "    info = variaveis_abertas[var]\n",
    "    \n",
    "    if len(df_cat) > 0:\n",
    "        cores = plt.cm.get_cmap(['Blues', 'Greens', 'Oranges'][idx])(np.linspace(0.3, 0.8, len(df_cat)))[::-1]\n",
    "        \n",
    "        bars = ax.barh(df_cat['Categoria'], df_cat['% Respondentes'], color=cores, edgecolor='white')\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xlabel('% dos Respondentes')\n",
    "        ax.set_title(info['nome_curto'], fontsize=12, fontweight='bold')\n",
    "        \n",
    "        for bar, pct in zip(bars, df_cat['% Respondentes']):\n",
    "            ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{pct}%', va='center', fontsize=9)\n",
    "\n",
    "plt.suptitle('Categorias Tem√°ticas Identificadas', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('grafico_categorias_tematicas_etapa6.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nGr√°fico salvo como: grafico_categorias_tematicas_etapa6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Resumo Executivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"RESUMO EXECUTIVO - ETAPA 6\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä VIS√ÉO GERAL DAS RESPOSTAS ABERTAS\n",
    "\n",
    "   Total de quest√µes analisadas: {len(variaveis_abertas)}\n",
    "   Taxa m√©dia de resposta: {df_estatisticas['% Preenchimento'].mean():.1f}%\n",
    "   Quest√£o com maior taxa: {df_estatisticas.loc[df_estatisticas['% Preenchimento'].idxmax(), 'Nome Curto']} ({df_estatisticas['% Preenchimento'].max()}%)\n",
    "   Quest√£o com menor taxa: {df_estatisticas.loc[df_estatisticas['% Preenchimento'].idxmin(), 'Nome Curto']} ({df_estatisticas['% Preenchimento'].min()}%)\n",
    "\n",
    "üìå PRINCIPAIS TEMAS IDENTIFICADOS\n",
    "\"\"\")\n",
    "\n",
    "for var, df_cat in resultados_categorizacao.items():\n",
    "    info = variaveis_abertas[var]\n",
    "    if len(df_cat) > 0:\n",
    "        top_cat = df_cat.iloc[0]\n",
    "        print(f\"   ‚Ä¢ {info['nome_curto']}: \\\"{top_cat['Categoria']}\\\" ({top_cat['% Respondentes']}%)\")\n",
    "\n",
    "print(f\"\"\"\n",
    "üìå TERMOS MAIS FREQUENTES (GLOBAL)\n",
    "\"\"\")\n",
    "\n",
    "for var, info in list(variaveis_abertas.items())[:3]:\n",
    "    if var in frequencias_termos and len(frequencias_termos[var]) > 0:\n",
    "        top_termos = frequencias_termos[var].head(3)['Termo'].tolist()\n",
    "        print(f\"   ‚Ä¢ {info['nome_curto']}: {', '.join(top_termos)}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "üìå MATERIAIS GERADOS PARA AN√ÅLISE MANUAL\n",
    "\n",
    "   ‚Ä¢ Amostra de {len(amostra)} respostas ({PERCENTUAL_AMOSTRA*100:.0f}%) para codifica√ß√£o\n",
    "   ‚Ä¢ {len(df_citacoes)} cita√ß√µes representativas selecionadas\n",
    "   ‚Ä¢ {len(df_citacoes_vinculo)} cita√ß√µes estratificadas por v√≠nculo\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Salvar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar todas as tabelas em um arquivo Excel com m√∫ltiplas abas\n",
    "with pd.ExcelWriter(ARQUIVO_SAIDA_EXCEL, engine='openpyxl') as writer:\n",
    "    # Estat√≠sticas gerais\n",
    "    df_estatisticas.to_excel(writer, sheet_name='Estatisticas_Gerais', index=False)\n",
    "    \n",
    "    # Frequ√™ncia de termos\n",
    "    for var, freq in frequencias_termos.items():\n",
    "        nome_aba = f'Termos_{variaveis_abertas[var][\"nome_curto\"][:15]}'\n",
    "        freq.to_excel(writer, sheet_name=nome_aba, index=False)\n",
    "    \n",
    "    # Frequ√™ncia de bigramas\n",
    "    for var, freq in frequencias_bigramas.items():\n",
    "        if len(freq) > 0:\n",
    "            nome_aba = f'Bigr_{variaveis_abertas[var][\"nome_curto\"][:15]}'\n",
    "            freq.to_excel(writer, sheet_name=nome_aba, index=False)\n",
    "    \n",
    "    # Categoriza√ß√£o tem√°tica\n",
    "    for var, df_cat in resultados_categorizacao.items():\n",
    "        nome_aba = f'Cat_{variaveis_abertas[var][\"nome_curto\"][:15]}'\n",
    "        df_cat.to_excel(writer, sheet_name=nome_aba, index=False)\n",
    "\n",
    "print(f\"‚úÖ An√°lises salvas em: {ARQUIVO_SAIDA_EXCEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar cita√ß√µes representativas\n",
    "with pd.ExcelWriter(ARQUIVO_SAIDA_CITACOES, engine='openpyxl') as writer:\n",
    "    df_citacoes.to_excel(writer, sheet_name='Citacoes_Gerais', index=False)\n",
    "    df_citacoes_vinculo.to_excel(writer, sheet_name='Citacoes_por_Vinculo', index=False)\n",
    "\n",
    "print(f\"‚úÖ Cita√ß√µes salvas em: {ARQUIVO_SAIDA_CITACOES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar relat√≥rio em Markdown\n",
    "relatorio = f\"\"\"# RELAT√ìRIO DE AN√ÅLISE QUALITATIVA DAS RESPOSTAS ABERTAS\n",
    "## Etapa 6 ‚Äî Consulta √† Comunidade UFPE sobre o Uso de IA\n",
    "\n",
    "**Data de execu√ß√£o:** {datetime.now().strftime(\"%d/%m/%Y √†s %H:%M\")}\n",
    "\n",
    "---\n",
    "\n",
    "## 1. VIS√ÉO GERAL DAS RESPOSTAS\n",
    "\n",
    "| Quest√£o | Respostas | % Preenchimento | Comp. M√©dio |\n",
    "|---------|-----------|-----------------|-------------|\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df_estatisticas.iterrows():\n",
    "    relatorio += f\"| {row['Nome Curto']} | {row['Respostas']} | {row['% Preenchimento']}% | {row['Comp. M√©dio (chars)']:.0f} chars |\\n\"\n",
    "\n",
    "relatorio += f\"\"\"\n",
    "---\n",
    "\n",
    "## 2. CATEGORIAS TEM√ÅTICAS IDENTIFICADAS\n",
    "\n",
    "### 2.1 Benef√≠cios Percebidos\n",
    "\n",
    "| Categoria | Men√ß√µes | % Respondentes |\n",
    "|-----------|---------|----------------|\n",
    "\"\"\"\n",
    "\n",
    "if 'Beneficios_Percebidos' in resultados_categorizacao:\n",
    "    for _, row in resultados_categorizacao['Beneficios_Percebidos'].iterrows():\n",
    "        relatorio += f\"| {row['Categoria']} | {row['Men√ß√µes']} | {row['% Respondentes']}% |\\n\"\n",
    "\n",
    "relatorio += f\"\"\"\n",
    "### 2.2 Riscos e Preocupa√ß√µes\n",
    "\n",
    "| Categoria | Men√ß√µes | % Respondentes |\n",
    "|-----------|---------|----------------|\n",
    "\"\"\"\n",
    "\n",
    "if 'Riscos_Preocupacoes' in resultados_categorizacao:\n",
    "    for _, row in resultados_categorizacao['Riscos_Preocupacoes'].iterrows():\n",
    "        relatorio += f\"| {row['Categoria']} | {row['Men√ß√µes']} | {row['% Respondentes']}% |\\n\"\n",
    "\n",
    "relatorio += f\"\"\"\n",
    "### 2.3 Medidas para Uso √âtico\n",
    "\n",
    "| Categoria | Men√ß√µes | % Respondentes |\n",
    "|-----------|---------|----------------|\n",
    "\"\"\"\n",
    "\n",
    "if 'Medidas_Uso_Etico' in resultados_categorizacao:\n",
    "    for _, row in resultados_categorizacao['Medidas_Uso_Etico'].iterrows():\n",
    "        relatorio += f\"| {row['Categoria']} | {row['Men√ß√µes']} | {row['% Respondentes']}% |\\n\"\n",
    "\n",
    "relatorio += f\"\"\"\n",
    "---\n",
    "\n",
    "## 3. CITA√á√ïES REPRESENTATIVAS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for var, info in list(variaveis_abertas.items())[:3]:\n",
    "    relatorio += f\"### {info['nome_curto']}\\n\\n\"\n",
    "    citacoes_var = df_citacoes[df_citacoes['Vari√°vel'] == var]['Cita√ß√£o'].head(3).tolist()\n",
    "    for i, cit in enumerate(citacoes_var, 1):\n",
    "        cit_truncada = cit[:300] + '...' if len(cit) > 300 else cit\n",
    "        relatorio += f\"> *\\\"{cit_truncada}\\\"*\\n\\n\"\n",
    "\n",
    "relatorio += f\"\"\"\n",
    "---\n",
    "\n",
    "## 4. TERMOS MAIS FREQUENTES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for var, info in list(variaveis_abertas.items())[:3]:\n",
    "    relatorio += f\"### {info['nome_curto']}\\n\\n\"\n",
    "    if var in frequencias_termos and len(frequencias_termos[var]) > 0:\n",
    "        relatorio += \"| # | Termo | Frequ√™ncia |\\n|---|-------|------------|\\n\"\n",
    "        for _, row in frequencias_termos[var].head(10).iterrows():\n",
    "            relatorio += f\"| {row['Ranking']} | {row['Termo']} | {row['Frequ√™ncia']} |\\n\"\n",
    "    relatorio += \"\\n\"\n",
    "\n",
    "relatorio += f\"\"\"\n",
    "---\n",
    "\n",
    "## 5. MATERIAIS PARA AN√ÅLISE MANUAL\n",
    "\n",
    "| Arquivo | Descri√ß√£o |\n",
    "|---------|----------|\n",
    "| `{ARQUIVO_SAIDA_AMOSTRA}` | Amostra de {len(amostra)} respostas ({PERCENTUAL_AMOSTRA*100:.0f}%) para codifica√ß√£o manual |\n",
    "| `{ARQUIVO_SAIDA_CITACOES}` | Cita√ß√µes representativas selecionadas |\n",
    "\n",
    "### Instru√ß√µes para Codifica√ß√£o Manual\n",
    "\n",
    "1. Abra o arquivo `{ARQUIVO_SAIDA_AMOSTRA}`\n",
    "2. Para cada resposta, preencha a coluna `_CODIGO` com a categoria tem√°tica identificada\n",
    "3. Use a coluna `_OBS` para observa√ß√µes adicionais\n",
    "4. Recomenda-se que dois codificadores independentes realizem a an√°lise\n",
    "5. Calcule o √≠ndice Kappa para verificar a concord√¢ncia entre codificadores\n",
    "\n",
    "---\n",
    "\n",
    "## 6. ARQUIVOS GERADOS\n",
    "\n",
    "| Arquivo | Descri√ß√£o |\n",
    "|---------|----------|\n",
    "| `{ARQUIVO_SAIDA_EXCEL}` | An√°lise de frequ√™ncia de termos e categorias |\n",
    "| `{ARQUIVO_SAIDA_AMOSTRA}` | Amostra para an√°lise manual |\n",
    "| `{ARQUIVO_SAIDA_CITACOES}` | Cita√ß√µes representativas |\n",
    "| `grafico_comprimento_respostas_etapa6.png` | Distribui√ß√£o do comprimento |\n",
    "| `grafico_frequencia_termos_etapa6.png` | Termos mais frequentes |\n",
    "| `grafico_nuvens_completo_etapa6.png` | Painel de nuvens de palavras |\n",
    "| `grafico_nuvem_[variavel]_etapa6.png` | Nuvens individuais |\n",
    "| `grafico_categorias_tematicas_etapa6.png` | Categorias tem√°ticas |\n",
    "\n",
    "---\n",
    "\n",
    "## 7. LIMITA√á√ïES E PR√ìXIMOS PASSOS\n",
    "\n",
    "**Limita√ß√µes desta an√°lise autom√°tica:**\n",
    "- A categoriza√ß√£o por palavras-chave √© aproximada e deve ser validada manualmente\n",
    "- Nuances e contexto podem ser perdidos na an√°lise automatizada\n",
    "- Recomenda-se an√°lise manual da amostra para refinamento das categorias\n",
    "\n",
    "**Pr√≥ximos passos recomendados:**\n",
    "1. Realizar codifica√ß√£o manual da amostra de 10%\n",
    "2. Refinar o codebook com base nos achados\n",
    "3. Calcular √≠ndice Kappa entre codificadores\n",
    "4. Expandir an√°lise para toda a base ap√≥s valida√ß√£o\n",
    "\n",
    "---\n",
    "\n",
    "*Relat√≥rio gerado automaticamente em {datetime.now().strftime(\"%d/%m/%Y √†s %H:%M\")}*\n",
    "\"\"\"\n",
    "\n",
    "# Salvar relat√≥rio\n",
    "with open(ARQUIVO_SAIDA_RELATORIO, \"w\", encoding='utf-8') as f:\n",
    "    f.write(relatorio)\n",
    "\n",
    "print(f\"‚úÖ Relat√≥rio salvo em: {ARQUIVO_SAIDA_RELATORIO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ETAPA 6 CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "üìÅ ARQUIVOS GERADOS:\n",
    "\n",
    "   üìä Dados:\n",
    "      ‚Ä¢ {ARQUIVO_SAIDA_EXCEL}\n",
    "      ‚Ä¢ {ARQUIVO_SAIDA_AMOSTRA}\n",
    "      ‚Ä¢ {ARQUIVO_SAIDA_CITACOES}\n",
    "\n",
    "   üìà Gr√°ficos:\n",
    "      ‚Ä¢ grafico_comprimento_respostas_etapa6.png\n",
    "      ‚Ä¢ grafico_frequencia_termos_etapa6.png\n",
    "      ‚Ä¢ grafico_nuvens_completo_etapa6.png\n",
    "      ‚Ä¢ grafico_nuvem_[variavel]_etapa6.png (7 arquivos)\n",
    "      ‚Ä¢ grafico_categorias_tematicas_etapa6.png\n",
    "\n",
    "   üìù Relat√≥rio:\n",
    "      ‚Ä¢ {ARQUIVO_SAIDA_RELATORIO}\n",
    "\n",
    "‚ñ∂Ô∏è  PR√ìXIMA ETAPA: Etapa 7 - S√≠ntese e Elabora√ß√£o de Recomenda√ß√µes\n",
    "\n",
    "‚ö†Ô∏è  IMPORTANTE: Antes de prosseguir para a Etapa 7, recomenda-se:\n",
    "      1. Revisar a amostra gerada ({ARQUIVO_SAIDA_AMOSTRA})\n",
    "      2. Realizar codifica√ß√£o manual com dois codificadores\n",
    "      3. Calcular √≠ndice Kappa para valida√ß√£o\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resumo dos Arquivos\n",
    "\n",
    "### Entrada\n",
    "| Arquivo | Origem |\n",
    "|---------|--------|\n",
    "| `dados_limpos_etapa1.xlsx` | Etapa 1 |\n",
    "\n",
    "### Sa√≠da\n",
    "| Arquivo | Descri√ß√£o |\n",
    "|---------|----------|\n",
    "| `qualitativa_etapa6.xlsx` | An√°lise de frequ√™ncia de termos e categorias tem√°ticas |\n",
    "| `amostra_analise_etapa6.xlsx` | Amostra de 10% para codifica√ß√£o manual |\n",
    "| `citacoes_representativas_etapa6.xlsx` | Cita√ß√µes selecionadas por quest√£o e v√≠nculo |\n",
    "| `grafico_comprimento_respostas_etapa6.png` | Distribui√ß√£o do comprimento das respostas |\n",
    "| `grafico_frequencia_termos_etapa6.png` | Top 10 termos por quest√£o |\n",
    "| `grafico_nuvens_completo_etapa6.png` | Painel com todas as nuvens de palavras |\n",
    "| `grafico_nuvem_[variavel]_etapa6.png` | Nuvens individuais (7 arquivos) |\n",
    "| `grafico_categorias_tematicas_etapa6.png` | Categorias tem√°ticas identificadas |\n",
    "| `relatorio_qualitativa_etapa6.md` | Relat√≥rio completo da an√°lise qualitativa |\n",
    "\n",
    "---\n",
    "\n",
    "**Pr√≥xima etapa:** Etapa 7 - S√≠ntese e Elabora√ß√£o de Recomenda√ß√µes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
