{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPA 1: Prepara√ß√£o e Limpeza dos Dados\n",
    "\n",
    "## Consulta √† Comunidade UFPE sobre o Uso de Intelig√™ncia Artificial\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo:** Garantir a qualidade e integridade dos dados antes das an√°lises.\n",
    "\n",
    "**Procedimentos:**\n",
    "1. Remover as respostas sem consentimento de participa√ß√£o\n",
    "2. Excluir a coluna vazia identificada (\"Coluna 1\")\n",
    "3. Padronizar categorias de v√≠nculo institucional\n",
    "4. Verificar e tratar valores ausentes (missing data)\n",
    "5. Criar vari√°vel derivada \"Vinculo_Padronizado\"\n",
    "\n",
    "**Produto:** Base de dados tratada com N = 2.164 registros v√°lidos.\n",
    "\n",
    "**Crit√©rio de Valida√ß√£o:** Relat√≥rio de limpeza documentando todas as transforma√ß√µes realizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√£o de bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes de exibi√ß√£o\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Bibliotecas carregadas com sucesso!\")\n",
    "print(f\"Pandas vers√£o: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURA√á√ÉO: Altere o caminho do arquivo conforme necess√°rio\n",
    "# ============================================================================\n",
    "\n",
    "ARQUIVO_ENTRADA = \"Consulta_a__Comunidade_UFPE_sobre_o_Uso_de_Intelige_ncia_Artificial__respostas_.xlsx\"\n",
    "ARQUIVO_SAIDA = \"dados_limpos_etapa1.xlsx\"\n",
    "ARQUIVO_SAIDA_CSV = \"dados_limpos_etapa1.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento dos Dados Originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados originais\n",
    "df_original = pd.read_excel(f\"data/{ARQUIVO_ENTRADA}\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DADOS ORIGINAIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total de registros: {len(df_original)}\")\n",
    "print(f\"Total de colunas: {len(df_original.columns)}\")\n",
    "print(f\"\\nColunas dispon√≠veis:\")\n",
    "for i, col in enumerate(df_original.columns, 1):\n",
    "    print(f\"  {i:2}. {col[:80]}{'...' if len(col) > 80 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar primeiras linhas\n",
    "df_original.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Procedimento 1: Remo√ß√£o de Respostas sem Consentimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar coluna de consentimento\n",
    "col_consentimento = 'Voc√™ leu as informa√ß√µes acima e concorda em participar voluntariamente desta consulta p√∫blica, ciente de que suas respostas s√£o an√¥nimas?'\n",
    "\n",
    "# Verificar distribui√ß√£o do consentimento\n",
    "print(\"Distribui√ß√£o do consentimento:\")\n",
    "print(df_original[col_consentimento].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar apenas os que consentiram\n",
    "df = df_original[df_original[col_consentimento] == 'Sim, concordo em participar'].copy()\n",
    "\n",
    "n_removidos = len(df_original) - len(df)\n",
    "print(f\"Registros sem consentimento removidos: {n_removidos}\")\n",
    "print(f\"Registros mantidos: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Procedimento 2: Exclus√£o de Coluna Vazia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar colunas completamente vazias\n",
    "colunas_vazias = df.columns[df.isna().all()].tolist()\n",
    "print(f\"Colunas completamente vazias identificadas: {colunas_vazias}\")\n",
    "\n",
    "# Remover colunas vazias\n",
    "if colunas_vazias:\n",
    "    df = df.drop(columns=colunas_vazias)\n",
    "    print(f\"Colunas removidas: {colunas_vazias}\")\n",
    "    \n",
    "print(f\"Total de colunas ap√≥s remo√ß√£o: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Procedimento 3: Padroniza√ß√£o de V√≠nculos Institucionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar coluna de v√≠nculo\n",
    "col_vinculo = 'V√≠nculo com a UFPE'\n",
    "\n",
    "# Remover espa√ßos extras\n",
    "df[col_vinculo] = df[col_vinculo].str.strip()\n",
    "\n",
    "# Verificar valores √∫nicos antes da padroniza√ß√£o\n",
    "print(f\"Valores √∫nicos ANTES da padroniza√ß√£o: {df[col_vinculo].nunique()}\")\n",
    "print(\"\\nDistribui√ß√£o original:\")\n",
    "print(df[col_vinculo].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de mapeamento para padroniza√ß√£o\n",
    "mapeamento_vinculo = {\n",
    "    # Discentes de Gradua√ß√£o\n",
    "    'Discente de Gradua√ß√£o': 'Discente de Gradua√ß√£o',\n",
    "    'Discente': 'Discente de Gradua√ß√£o',\n",
    "    'Sou egresso de bach. de Educa√ß√£o F√≠sica e atualmente discente de Letras': 'Discente de Gradua√ß√£o',\n",
    "    \n",
    "    # Discentes de P√≥s-Gradua√ß√£o\n",
    "    'Discente de P√≥s-Gradua√ß√£o': 'Discente de P√≥s-Gradua√ß√£o',\n",
    "    'Discente de P√≥s-Gradua√ß√£o & T√©cnico Administrativo': 'Discente de P√≥s-Gradua√ß√£o',\n",
    "    'Discente de P√≥s-Gradua√ß√£o e T√©cnico-administrativo': 'Discente de P√≥s-Gradua√ß√£o',\n",
    "    'T√©cnico-administrativo e discente da p√≥s-gradua√ß√£o': 'Discente de P√≥s-Gradua√ß√£o',\n",
    "    'T√©cnico-administrativo e discente de p√≥s-gradua√ß√£o': 'Discente de P√≥s-Gradua√ß√£o',\n",
    "    'T√©cnica e Discente de p√≥s gradua√ß√£o': 'Discente de P√≥s-Gradua√ß√£o',\n",
    "    \n",
    "    # Docentes\n",
    "    'Docente': 'Docente',\n",
    "    'Docente aposentado.': 'Docente',\n",
    "    'Docente da p√≥s-gradua√ß√£o': 'Docente',\n",
    "    'p√≥s-doc': 'Docente',\n",
    "    'P√≥s-doutor do Programa de P√≥s-gradua√ß√£o em Educa√ß√£o F√≠sica.': 'Docente',\n",
    "    'Professor substituto': 'Docente',\n",
    "    'Professor Visitante': 'Docente',\n",
    "    \n",
    "    # T√©cnico-administrativo\n",
    "    'T√©cnico-administrativo': 'T√©cnico-administrativo',\n",
    "    'T√©cnico adm e docente': 'T√©cnico-administrativo',\n",
    "    'T√©cnico em Assuntos Educacionais': 'T√©cnico-administrativo',\n",
    "    'Funcion√°rio FADE': 'T√©cnico-administrativo',\n",
    "    \n",
    "    # Egressos\n",
    "    'Egresso de Gradua√ß√£o': 'Egresso',\n",
    "    'Egresso de P√≥s-Gradua√ß√£o': 'Egresso',\n",
    "    'Egresso': 'Egresso',\n",
    "    'Rec√©m Graduado': 'Egresso',\n",
    "    'Ex-discente de gradua√ß√£o e de p√≥s-gradua√ß√£o': 'Egresso',\n",
    "    'Egresso de P√≥s-Gradua√ß√£o, atualmente peaquisador em um projeto de pesquisa': 'Egresso'\n",
    "}\n",
    "\n",
    "# Criar vari√°vel padronizada\n",
    "df['Vinculo_Padronizado'] = df[col_vinculo].map(mapeamento_vinculo)\n",
    "\n",
    "print(\"Mapeamento aplicado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se h√° valores n√£o mapeados\n",
    "nao_mapeados = df[df['Vinculo_Padronizado'].isna()][col_vinculo].unique()\n",
    "\n",
    "if len(nao_mapeados) > 0:\n",
    "    print(\"‚ö†Ô∏è ATEN√á√ÉO: Valores n√£o mapeados encontrados:\")\n",
    "    for v in nao_mapeados:\n",
    "        print(f\"   - '{v}'\")\n",
    "    print(\"\\nAdicione estes valores ao dicion√°rio de mapeamento acima.\")\n",
    "else:\n",
    "    print(\"‚úì Todos os valores foram mapeados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar distribui√ß√£o ap√≥s padroniza√ß√£o\n",
    "print(f\"Valores √∫nicos AP√ìS padroniza√ß√£o: {df['Vinculo_Padronizado'].nunique()}\")\n",
    "print(\"\\nDistribui√ß√£o padronizada:\")\n",
    "\n",
    "dist_vinculo = df['Vinculo_Padronizado'].value_counts()\n",
    "for vinculo, count in dist_vinculo.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   ‚Ä¢ {vinculo}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   TOTAL: {len(df)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Procedimento 4: Renomea√ß√£o de Vari√°veis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de renomea√ß√£o para nomes mais curtos e padronizados\n",
    "nomes_curtos = {\n",
    "    'Carimbo de data/hora': 'Timestamp',\n",
    "    col_consentimento: 'Consentimento',\n",
    "    'V√≠nculo com a UFPE': 'Vinculo_Original',\n",
    "    'Centro, Unidade Acad√™mica ou Unidade Gestora': 'Centro_Unidade',\n",
    "    'Curso (para discentes)': 'Curso',\n",
    "    'Voc√™ j√° utilizou alguma ferramenta de IA (como ChatGPT, Copilot, Gemini, Claude, Perplexity etc.)?': 'Frequencia_Uso_IA',\n",
    "    'Em quais contextos voc√™ utiliza ou pretende utilizar ferramentas de IA?': 'Contextos_Uso',\n",
    "    'Quais benef√≠cios voc√™ percebe no uso da IA na UFPE?': 'Beneficios_Percebidos',\n",
    "    'Quais riscos ou preocupa√ß√µes voc√™ identifica no uso da IA na universidade?': 'Riscos_Preocupacoes',\n",
    "    'O uso que voc√™ faz (ou faria) de ferramentas de IA √© predominantemente:': 'Tipo_Uso',\n",
    "    'Avalie as afirma√ß√µes abaixo de acordo com seu grau de concord√¢ncia. [A intelig√™ncia artificial j√° n√£o √© mais uma op√ß√£o, √© uma realidade com a qual precisamos aprender a lidar.]': 'Likert_IA_Realidade',\n",
    "    'Avalie as afirma√ß√µes abaixo de acordo com seu grau de concord√¢ncia. [O uso √©tico e respons√°vel da intelig√™ncia artificial requer diretrizes e normativas claras.]': 'Likert_Diretrizes_Eticas',\n",
    "    'Avalie as afirma√ß√µes abaixo de acordo com seu grau de concord√¢ncia. [A UFPE deve oferecer diretrizes sobre o uso de IA em trabalhos e avalia√ß√µes de atividades dos discentes.]': 'Likert_Diretrizes_Avaliacoes',\n",
    "    'Avalie as afirma√ß√µes abaixo de acordo com seu grau de concord√¢ncia. [O uso de IA deve ser incentivado como ferramenta de apoio, desde que usado de forma respons√°vel.]': 'Likert_Incentivo_IA',\n",
    "    'Avalie as afirma√ß√µes abaixo de acordo com seu grau de concord√¢ncia. [A universidade deve promover mais debates, orienta√ß√µes de uso e espa√ßos de reflex√£o sobre os impactos da IA na sociedade.]': 'Likert_Debates_Impactos',\n",
    "    'Na sua percep√ß√£o, como a IA pode impactar a produ√ß√£o autoral?': 'Impacto_Producao_Autoral',\n",
    "    'Na sua percep√ß√£o, como a IA pode impactar a integridade acad√™mica?': 'Impacto_Integridade_Academica',\n",
    "    'Que medidas a UFPE deveria adotar para garantir o uso √©tico, transparente e respons√°vel da IA?': 'Medidas_Uso_Etico',\n",
    "    'Quais temas devem ser priorizados no Plano Institucional de IA da UFPE?': 'Temas_Prioritarios',\n",
    "    'Como a UFPE deve estruturar sua governan√ßa em rela√ß√£o √† IA?': 'Estrutura_Governanca',\n",
    "    'Voc√™ se sente preparado(a) para usar ferramentas de IA de forma √©tica e eficaz?': 'Preparacao_Uso_Etico',\n",
    "    'Que tipos de forma√ß√£o ou de suporte institucional voc√™ considera mais importantes?': 'Tipos_Formacao',\n",
    "    'Deixe aqui sugest√µes ou coment√°rios finais.': 'Comentarios_Finais'\n",
    "}\n",
    "\n",
    "# Aplicar renomea√ß√£o\n",
    "df = df.rename(columns=nomes_curtos)\n",
    "\n",
    "print(\"Colunas renomeadas:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"  {i:2}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Procedimento 5: An√°lise de Valores Ausentes (Missing Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de missing values\n",
    "print(\"=\" * 70)\n",
    "print(\"AN√ÅLISE DE VALORES AUSENTES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "missing_report = []\n",
    "for col in df.columns:\n",
    "    n_missing = df[col].isna().sum()\n",
    "    pct_missing = (n_missing / len(df)) * 100\n",
    "    missing_report.append({\n",
    "        'Vari√°vel': col,\n",
    "        'N_Missing': n_missing,\n",
    "        'Pct_Missing': round(pct_missing, 1)\n",
    "    })\n",
    "\n",
    "# Criar DataFrame do relat√≥rio\n",
    "df_missing = pd.DataFrame(missing_report)\n",
    "df_missing = df_missing.sort_values('N_Missing', ascending=False)\n",
    "\n",
    "# Exibir apenas vari√°veis com missing\n",
    "print(\"\\nVari√°veis com valores ausentes:\")\n",
    "print(\"-\" * 50)\n",
    "df_com_missing = df_missing[df_missing['N_Missing'] > 0]\n",
    "print(df_com_missing.to_string(index=False))\n",
    "\n",
    "print(f\"\\nVari√°veis sem valores ausentes: {len(df_missing[df_missing['N_Missing'] == 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o dos missing values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtrar apenas vari√°veis com missing > 0\n",
    "df_plot = df_com_missing[df_com_missing['Pct_Missing'] > 0].copy()\n",
    "\n",
    "if len(df_plot) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.barh(df_plot['Vari√°vel'], df_plot['Pct_Missing'], color='steelblue')\n",
    "    ax.set_xlabel('% de Valores Ausentes')\n",
    "    ax.set_title('Valores Ausentes por Vari√°vel')\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Adicionar labels nas barras\n",
    "    for bar, pct in zip(bars, df_plot['Pct_Missing']):\n",
    "        ax.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2, \n",
    "                f'{pct}%', va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('missing_values_etapa1.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\nGr√°fico salvo como: missing_values_etapa1.png\")\n",
    "else:\n",
    "    print(\"Nenhuma vari√°vel com valores ausentes para plotar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Resumo da Etapa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RESUMO DA ETAPA 1 - LIMPEZA CONCLU√çDA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìã TRANSFORMA√á√ïES REALIZADAS:\n",
    "\n",
    "   1. Remo√ß√£o de registros sem consentimento\n",
    "      ‚Ä¢ Registros removidos: {n_removidos}\n",
    "      ‚Ä¢ Registros mantidos: {len(df)}\n",
    "\n",
    "   2. Exclus√£o de coluna vazia\n",
    "      ‚Ä¢ Coluna removida: 'Coluna 1'\n",
    "      ‚Ä¢ Total de colunas: {len(df.columns)}\n",
    "\n",
    "   3. Padroniza√ß√£o de v√≠nculos institucionais\n",
    "      ‚Ä¢ Categorias originais: 26\n",
    "      ‚Ä¢ Categorias padronizadas: {df['Vinculo_Padronizado'].nunique()}\n",
    "\"\"\")\n",
    "\n",
    "for vinculo, count in df['Vinculo_Padronizado'].value_counts().items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"        - {vinculo}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\"\"\n",
    "   4. Renomea√ß√£o de colunas para facilitar an√°lise\n",
    "      ‚Ä¢ {len(df.columns)} colunas renomeadas com nomes curtos\n",
    "\n",
    "   5. Documenta√ß√£o de valores ausentes\n",
    "      ‚Ä¢ Vari√°veis com missing identificadas e documentadas\n",
    "\n",
    "üìÅ BASE DE DADOS FINAL:\n",
    "   ‚Ä¢ Registros v√°lidos: {len(df)}\n",
    "   ‚Ä¢ Vari√°veis: {len(df.columns)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Salvar Base de Dados Limpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar em Excel\n",
    "df.to_excel(ARQUIVO_SAIDA, index=False)\n",
    "print(f\"‚úÖ Base de dados limpa salva em: {ARQUIVO_SAIDA}\")\n",
    "\n",
    "# Salvar em CSV (opcional)\n",
    "df.to_csv(ARQUIVO_SAIDA_CSV, index=False)\n",
    "print(f\"‚úÖ Base de dados limpa salva em: {ARQUIVO_SAIDA_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar amostra da base final\n",
    "print(\"Amostra da base de dados limpa:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Gera√ß√£o do Relat√≥rio de Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar relat√≥rio de limpeza em Markdown\n",
    "relatorio = f\"\"\"# RELAT√ìRIO DE LIMPEZA DE DADOS\n",
    "## Etapa 1 ‚Äî Consulta √† Comunidade UFPE sobre o Uso de IA\n",
    "\n",
    "**Data de execu√ß√£o:** {datetime.now().strftime(\"%d/%m/%Y √†s %H:%M\")}\n",
    "\n",
    "---\n",
    "\n",
    "## 1. DADOS ORIGINAIS\n",
    "\n",
    "| M√©trica | Valor |\n",
    "|---------|-------|\n",
    "| Total de registros | {len(df_original)} |\n",
    "| Total de colunas | {len(df_original.columns)} |\n",
    "\n",
    "---\n",
    "\n",
    "## 2. TRANSFORMA√á√ïES REALIZADAS\n",
    "\n",
    "### 2.1 Remo√ß√£o de registros sem consentimento\n",
    "\n",
    "| Descri√ß√£o | Quantidade |\n",
    "|-----------|------------|\n",
    "| Registros sem consentimento removidos | {n_removidos} |\n",
    "| Registros mantidos | {len(df)} |\n",
    "| Taxa de exclus√£o | {n_removidos/len(df_original)*100:.1f}% |\n",
    "\n",
    "### 2.2 Exclus√£o de coluna vazia\n",
    "\n",
    "| Coluna removida | Motivo |\n",
    "|-----------------|--------|\n",
    "| \"Coluna 1\" | Completamente vazia (100% missing) |\n",
    "\n",
    "### 2.3 Padroniza√ß√£o de v√≠nculos institucionais\n",
    "\n",
    "**De 26 categorias originais para {df['Vinculo_Padronizado'].nunique()} categorias padronizadas:**\n",
    "\n",
    "| Categoria Padronizada | Registros | % |\n",
    "|-----------------------|-----------|---|\n",
    "\"\"\"\n",
    "\n",
    "for vinculo, count in df['Vinculo_Padronizado'].value_counts().items():\n",
    "    pct = count / len(df) * 100\n",
    "    relatorio += f\"| {vinculo} | {count} | {pct:.1f}% |\\n\"\n",
    "\n",
    "relatorio += f\"\"\"| **TOTAL** | **{len(df)}** | **100%** |\n",
    "\n",
    "---\n",
    "\n",
    "## 3. AN√ÅLISE DE VALORES AUSENTES\n",
    "\n",
    "| Vari√°vel | N Missing | % Missing |\n",
    "|----------|-----------|----------|\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df_com_missing.iterrows():\n",
    "    relatorio += f\"| {row['Vari√°vel']} | {row['N_Missing']} | {row['Pct_Missing']}% |\\n\"\n",
    "\n",
    "relatorio += f\"\"\"\n",
    "**Vari√°veis completas (0% missing):** {len(df_missing[df_missing['N_Missing'] == 0])} vari√°veis\n",
    "\n",
    "---\n",
    "\n",
    "## 4. BASE DE DADOS FINAL\n",
    "\n",
    "| M√©trica | Valor |\n",
    "|---------|-------|\n",
    "| Total de registros v√°lidos | {len(df)} |\n",
    "| Total de vari√°veis | {len(df.columns)} |\n",
    "| Arquivo gerado | {ARQUIVO_SAIDA} |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. VALIDA√á√ÉO\n",
    "\n",
    "- [x] Todos os {len(df)} registros possuem consentimento v√°lido\n",
    "- [x] Coluna vazia removida\n",
    "- [x] 100% dos v√≠nculos mapeados para categorias padronizadas\n",
    "- [x] Nomes de vari√°veis padronizados\n",
    "- [x] Missing values documentados\n",
    "\n",
    "---\n",
    "\n",
    "*Relat√≥rio gerado automaticamente em {datetime.now().strftime(\"%d/%m/%Y √†s %H:%M\")}*\n",
    "\"\"\"\n",
    "\n",
    "# Salvar relat√≥rio\n",
    "with open(\"relatorio_limpeza_etapa1.md\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(relatorio)\n",
    "\n",
    "print(\"‚úÖ Relat√≥rio de limpeza salvo em: relatorio_limpeza_etapa1.md\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ETAPA 1 CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Arquivos Gerados\n",
    "\n",
    "| Arquivo | Descri√ß√£o |\n",
    "|---------|----------|\n",
    "| `dados_limpos_etapa1.xlsx` | Base de dados tratada |\n",
    "| `dados_limpos_etapa1.csv` | Base de dados tratada (CSV) |\n",
    "| `relatorio_limpeza_etapa1.md` | Relat√≥rio documentando transforma√ß√µes |\n",
    "| `missing_values_etapa1.png` | Gr√°fico de valores ausentes |\n",
    "\n",
    "---\n",
    "\n",
    "**Pr√≥xima etapa:** Etapa 2 - An√°lise do Perfil dos Respondentes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
